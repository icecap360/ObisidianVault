---
tags:
  - "#Ideas"
  - "#Incomplete"
topics:
---
# Key Ideas
- Encode a given token using its own value and the value of other tokens
- When encoding tokens, pay attention to the tokens that have similar keys to your query
- Find a subspace for encodings (the values), and a subspace where similar encodings point in the same direction.
    - The last subspace (for the keys) may be hard to understand, but it is a subspace that finds keys such that high q\*k == similar encodings
    - Note that I believe although keys and queries are computed using different change-of-basis matrices, they are still in the same subspace which allows dot product to be valid mapping
# Details
## What is attention?
* 
# Comments and Links
- 
# Reference
[https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
